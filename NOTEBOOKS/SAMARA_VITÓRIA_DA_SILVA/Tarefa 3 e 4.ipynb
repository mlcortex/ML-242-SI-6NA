{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f6447-6511-48ae-b94f-26cf41c1d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sejam bem-vindos ao Notebook destinado a explicação prática de uma validação cruzada. Antes de começar vale informar que o conjunto de dados\n",
    "#utilizado trata-se de informações sobre flores. Vamos nessa? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7749aad2-7389-4a31-a19a-7959699c240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Importando os dados e os transformando num DataFrame\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "#Para pré-visualizarmos nossos dados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76df8507-cbfb-47ab-9147-64fec2729968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de linhas e colunas\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dbc7817-877e-4bca-860a-d00b6a6e5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis independentes e a classe\n",
    "X = df.iloc[:, :-1]  # todas as colunas menos a última\n",
    "y = df.iloc[:, -1]   # apenas a última coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af175613-2674-4016-8f67-ed6827eaec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        0.333333\n",
       "Iris-versicolor    0.333333\n",
       "Iris-virginica     0.333333\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proporção da classe\n",
    "\n",
    "df['class'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df02c5e1-6142-4b4f-bcea-1bf436474442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas e colunas para os dados de treino: (120, 4)\n",
      "Quantidade de linhas e colunas para os dados de teste: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "#Importando a função que irá realizar a divisão dos dados em treino e teste\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "print(f\"Quantidade de linhas e colunas para os dados de treino: {X_train.shape}\")\n",
    "print(f\"Quantidade de linhas e colunas para os dados de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15828b3c-2776-4e23-861b-f0819bd071f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        0.333333\n",
       "Iris-virginica     0.333333\n",
       "Iris-versicolor    0.333333\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando o array y_train em uma série para analisar a \n",
    "# proporção das classes no conjunto de treino\n",
    "pd.Series(y_train).value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13a46c31-242a-42e2-9f35-f35c27bb6cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        0.333333\n",
       "Iris-virginica     0.333333\n",
       "Iris-versicolor    0.333333\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando o array y_test em uma série para analisar a \n",
    "# proporção das classes no conjunto de teste\n",
    "pd.Series(y_test).value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ced09a0-74c6-4e41-be0b-2092d5b8ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A regressão logística exige que as variáveis estejam escalonadas\n",
    "# (na mesma ordem de grandeza). \n",
    "# Para realizar o escalonamento é importada a função StandardScaler.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciando o StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Calcula os parâmetros da escala e aplica aos dados de treino, transformando-os\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Com os parâmetros já calculados, os dados de teste são escalonados \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56edc50f-eb56-47a1-b6af-80c8684f8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a função da regressão logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instanciando e treinando o modelo\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo as probabilidades das classes previstas\n",
    "y_pred_proba = modelo.predict_proba(X_test)\n",
    "\n",
    "# Obtendo as previsões do modelo\n",
    "y_pred = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0fd74107-b758-40e0-abe7-da7a5596a76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão foi de: 1.000\n",
      "A revocação foi de: 1.000\n",
      "A acurácia foi de: 1.000\n"
     ]
    }
   ],
   "source": [
    "# importando as funções para calcular a precisão e a revocação\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# importando a função para calcular a acurácia do modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "precisao = precision_score(y_test, y_pred, average = \"macro\")\n",
    "revocacao = recall_score(y_test, y_pred, average = \"macro\")\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"A precisão foi de: {precisao:.3f}\")\n",
    "print(f\"A revocação foi de: {revocacao:.3f}\")\n",
    "print(f\"A acurácia foi de: {acuracia:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffd360-df66-4181-9c50-9c94eb35c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Após isso vamos para a aplicação da nossa validação cruzada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f584a9a2-79e4-4550-adf1-2e404a05fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca Numpy, para manipulações algébricas\n",
    "import numpy as np\n",
    "\n",
    "# importando as funções Stratified K-Fold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Para realizar o escalonamento é importada a função StandardScaler.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# importando a função da regressão logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# importando as funções para calcular a precisão e a revocação\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# importando a função para calcular a acurácia do modelo\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7502c63c-d402-4efd-b2fa-89b5815b9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o número de folds\n",
    "k = 5\n",
    "\n",
    "# Inicializando a função StratifiedKFold\n",
    "folds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Criando listas para armazenar os valores de precisão, revocação e \n",
    "# acurácia em cada fold\n",
    "precisoes = list()\n",
    "revocacoes = list()\n",
    "acuracias = list()\n",
    "\n",
    "# Instanciando o StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Transformando X e y em respectivamente, um dataframe e uma série do pandas. \n",
    "# Isto é feito para se ter acesso aos índices de cada instância.\n",
    "\n",
    "X = df.drop(columns = [\"class\"], axis = 1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "801a2dfd-8ba3-4135-9fea-660ef27d02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n",
      "Precisão: 1.000\n",
      "Revocação: 1.000\n",
      "Acurácia: 1.000\n",
      "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n",
      "Precisão: 0.970\n",
      "Revocação: 0.967\n",
      "Acurácia: 0.967\n",
      "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n",
      "Precisão: 0.947\n",
      "Revocação: 0.933\n",
      "Acurácia: 0.933\n",
      "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n",
      "Precisão: 0.903\n",
      "Revocação: 0.900\n",
      "Acurácia: 0.900\n",
      "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n",
      "Precisão: 0.969\n",
      "Revocação: 0.967\n",
      "Acurácia: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Será aplicado o método \"split\" no objeto folds, que retornará uma lista \n",
    "# com os índices das instâncias que pertencem ao conjunto de treino e \n",
    "# outra com os índices das instâncias que pertencem ao conjunto de teste\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
    "\n",
    "    # Dividindo os dados em treino e teste para cada um dos folds\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # train_index e test_index: São os índices das instâncias do conjunto \n",
    "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
    "    \n",
    "    # Escalonando os dados. Todas as colunas serão passadas para uma \n",
    "    # distribuição normal, garantindo que as características estejam\n",
    "    # em uma mesma escala numérica\n",
    "    X_train = scaler.fit_transform(X_train) \n",
    "    X_test = scaler.transform(X_test) \n",
    "    \n",
    "    # instanciando e treinando o modelo\n",
    "    modelo = LogisticRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Obtendo as probabilidades das classes previstas\n",
    "    y_pred_proba = modelo.predict_proba(X_test)\n",
    "\n",
    "    # Obtendo as previsões do modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
    "    precisao = precision_score(y_test, y_pred, average = \"weighted\")\n",
    "    revocacao = recall_score(y_test, y_pred, average = \"weighted\")\n",
    "    acuracia = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
    "    precisoes.append(precisao)\n",
    "    revocacoes.append(revocacao)\n",
    "    acuracias.append(acuracia)\n",
    "    \n",
    "    # Exibindo as métricas para cada um dos folds\n",
    "    print(f\"Precisão: {precisao:.3f}\")\n",
    "    print(f\"Revocação: {revocacao:.3f}\")\n",
    "    print(f\"Acurácia: {acuracia:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f17e8eff-6461-4fbd-9e75-c0272ca1108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média da precisão: 0.958 +/- 0.032\n",
      "Média da revocação: 0.953 +/- 0.034\n",
      "Média da acurácia: 0.953 +/- 0.034\n"
     ]
    }
   ],
   "source": [
    "# Transformando as listas precisões, revocações, acurácias em arrays, \n",
    "# para fazer operações matemáticas\n",
    "precisoes = np.array(precisoes)\n",
    "revocacoes = np.array(revocacoes)\n",
    "acuracias = np.array(acuracias)\n",
    "   \n",
    "# Calculando a média de todas as precisões, revocações e acurácias \n",
    "media_precisao = np.mean(precisoes)\n",
    "media_revocacao = np.mean(revocacoes)\n",
    "media_acuracia = np.mean(acuracias)\n",
    "\n",
    "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
    "std_precisao = np.std(precisoes)\n",
    "std_revocacao = np.std(revocacoes)\n",
    "std_acuracia = np.std(acuracias)\n",
    "\n",
    "# Exibindo a média das precisões e revocações\n",
    "print(f\"Média da precisão: {media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
    "print(f\"Média da revocação: {media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
    "print(f\"Média da acurácia: {media_acuracia:.3f} +/- {std_acuracia:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cbde8-bc4f-49bd-ad44-c47860e73e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espero que você tenha gostado de todo esse processo! Vamos lá continuar evoluindo!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
